{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3144ee62",
   "metadata": {},
   "source": [
    "1.\tWhat are the key tasks involved in getting ready to work with machine learning modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570d84a4",
   "metadata": {},
   "source": [
    "1. Data collection and preparation: Machine learning models are only as good as the data they are trained on. Collecting and preparing high-quality data is a crucial step in the modeling process. This includes tasks such as identifying relevant data sources, cleaning and preprocessing the data, and splitting the data into training, validation, and testing sets.\n",
    "2. Problem formulation: In order to create an effective machine learning model, it is important to clearly define the problem you are trying to solve. This involves understanding the business context of the problem, defining the relevant variables and features, and selecting an appropriate model architecture.\n",
    "3. Feature engineering: Feature engineering involves selecting and creating features (i.e., variables) that are most relevant for the problem at hand. This can involve domain expertise, statistical analysis, and data visualization techniques.\n",
    "4. Model selection and training: Once the data is ready and the problem is defined, the next step is to select an appropriate model architecture and train it using the training data. This involves selecting the appropriate hyperparameters for the model, such as learning rate, regularization, and batch size.\n",
    "5. Model evaluation: After training the model, it is important to evaluate its performance on the validation and testing data sets. This can involve metrics such as accuracy, precision, recall, and F1-score.\n",
    "6. Model deployment and monitoring: Once the model has been trained and evaluated, it can be deployed in a production environment. However, it is important to monitor the model's performance over time to ensure that it continues to perform well and to identify any issues that may arise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0677ea",
   "metadata": {},
   "source": [
    "2. What are the different forms of data used in machine learning? Give a specific example for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695eb609",
   "metadata": {},
   "source": [
    "1. Structured Data: Structured data is highly organized and can be easily processed by machine learning algorithms. This type of data is typically stored in a tabular format, where each row represents an instance or observation and each column represents a feature or variable. An example of structured data is a spreadsheet containing customer demographic information and purchase history.\n",
    "2. Unstructured Data: Unstructured data is typically more difficult to process and analyze than structured data. This type of data is not organized in a predefined manner and can come in a variety of formats such as text, audio, or images. An example of unstructured data is a collection of customer reviews or social media posts.\n",
    "3. Semi-structured Data: Semi-structured data is a combination of structured and unstructured data. It has some organizational structure but also contains elements of unstructured data. An example of semi-structured data is an XML or JSON file containing customer data with nested elements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912826b",
   "metadata": {},
   "source": [
    "3. Distinguish:\n",
    "\n",
    "1.\tNumeric vs. categorical attributes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a2493",
   "metadata": {},
   "source": [
    "1. Numeric Attributes: Numeric attributes are those that contain numerical values. They can be continuous or discrete. Continuous numeric attributes can take on any value within a range, such as height or weight. Discrete numeric attributes can only take on a specific set of values, such as age or number of children.\n",
    "2. Categorical Attributes: Categorical attributes are those that contain values that belong to a specific set of categories. They can be nominal or ordinal. Nominal categorical attributes do not have an inherent order, such as gender or color. Ordinal categorical attributes have a specific order or ranking, such as education level or income bracket.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9be2951",
   "metadata": {},
   "source": [
    "3.\tFeature selection vs. dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee41bef",
   "metadata": {},
   "source": [
    "1. Feature Selection: Feature selection involves selecting a subset of the original features to use for training the machine learning model. This can be done manually by domain experts or automatically using algorithms. Feature selection is useful when there are many irrelevant or redundant features in the dataset that can negatively impact model performance. Examples of feature selection techniques include correlation-based feature selection and recursive feature elimination.\n",
    "2. Dimensionality Reduction: Dimensionality reduction involves transforming the original features into a lower-dimensional space while preserving the important information in the data. This can be done using techniques such as Principal Component Analysis (PCA) and t-SNE. Dimensionality reduction is useful when there are too many features to use for training the model, which can lead to overfitting or increased computational complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085d4efe",
   "metadata": {},
   "source": [
    "4. Make quick notes on any two of the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cbc3d1",
   "metadata": {},
   "source": [
    "\n",
    "1.\tThe histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12705a6f",
   "metadata": {},
   "source": [
    "A histogram is a graphical representation of the distribution of a continuous numerical variable. It consists of a series of bars, where the height of each bar represents the frequency of observations falling within a particular range or bin of values.\n",
    "Histograms are commonly used to visualize the shape of a dataset and to identify patterns or anomalies. The x-axis of a histogram represents the range of values for the variable being measured, while the y-axis represents the frequency or proportion of observations falling within each bin.\n",
    "Some common features of histograms include:\n",
    "• Bins: The intervals or ranges of values used to group the data into bars.\n",
    "• Frequency: The number of observations falling within each bin or range.\n",
    "• Density: The proportion of observations falling within each bin, calculated as frequency divided by the bin width.\n",
    "• Skewness: The degree to which the distribution of the data is asymmetric.\n",
    "• Kurtosis: The degree to which the distribution of the data has heavy tails or is peaked.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f3177",
   "metadata": {},
   "source": [
    "2.\tUse a scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a993d74f",
   "metadata": {},
   "source": [
    "3. A scatter plot is a type of plot that displays the relationship between two continuous numerical variables. Each point in the plot represents an observation or instance, with the x-axis and y-axis representing the values of the two variables being compared.\n",
    "4. Scatter plots are useful for identifying patterns or relationships between two variables, such as a positive or negative correlation. They can also be used to identify outliers or clusters of observations that may indicate subgroups or patterns in the data.\n",
    "5. For example, suppose we have a dataset containing information about houses, including the size of the house and its sale price. We can use a scatter plot to visualize the relationship between these two variables. The x-axis would represent the size of the house, while the y-axis would represent the sale price. Each point in the plot would represent a single house, with its position determined by its size and sale price.\n",
    "6. By examining the scatter plot, we can identify any patterns or relationships between the size of the house and its sale price. We can also identify any outliers or unusual observations that may require further investigation. This information can be used to build predictive models or make decisions about pricing and marketing strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863131e3",
   "metadata": {},
   "source": [
    "              3.PCA (Personal Computer Aid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29605848",
   "metadata": {},
   "source": [
    "PCA stands for Principal Component. PCA is a popular unsupervised dimensionality reduction technique used in machine learning and data analysis to transform a high-dimensional dataset into a lower-dimensional representation while retaining as much information as possible.\n",
    "PCA works by identifying the principal components of the dataset, which are linear combinations of the original features that capture the most variation in the data. The first principal component is the direction of maximum variance in the data, and each subsequent principal component is orthogonal to the previous ones and captures the remaining variation.\n",
    "PCA can be used for a variety of tasks, such as data visualization, feature extraction, and noise reduction. By reducing the dimensionality of the data, PCA can help simplify the analysis and visualization of complex datasets, and can also improve the performance of machine learning models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08c661",
   "metadata": {},
   "source": [
    "\n",
    "4.\tWhy is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative data are explored?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafbfcd5",
   "metadata": {},
   "source": [
    "1. It is necessary to investigate data to gain insights into the underlying patterns, relationships, and trends in the data, and to identify any issues or anomalies that may affect the accuracy or validity of any analyses or modeling performed on the data. Data investigation involves examining the data for missing values, outliers, inconsistencies, and other types of errors, as well as exploring the distributions of the variables and their relationships with each other.\n",
    "2. Both qualitative and quantitative data can benefit from data investigation, although the methods used may differ slightly depending on the type of data. Qualitative data, which includes non-numerical data such as text, images, and audio recordings, may require more exploratory analysis, such as text mining or content analysis, to identify themes and patterns in the data. Qualitative data may also require more subjective interpretation by the researcher, and the analysis may be more dependent on the context and cultural factors surrounding the data.\n",
    "3. Quantitative data, which includes numerical data such as counts, measurements, and ratings, may be more amenable to statistical analysis, such as descriptive statistics or hypothesis testing. However, quantitative data may also require careful consideration of issues such as missing data, outliers, and data transformations to ensure that the results are valid and reliable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab4df7",
   "metadata": {},
   "source": [
    "\n",
    "5.\tWhat are the various histogram shapes? What exactly are ‘bins'?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a025f7f",
   "metadata": {},
   "source": [
    "Histograms are a way to visualize the distribution of a numerical variable by grouping it into discrete intervals called \"bins\" and counting the number of observations that fall into each bin. The shape of a histogram can provide important insights into the underlying distribution of the data.\n",
    "Here are some common histogram shapes and what they may indicate about the distribution of the data:\n",
    "1. Normal distribution: a symmetric bell-shaped curve with the majority of the observations in the middle of the distribution, and fewer observations in the tails.\n",
    "2. Skewed distribution: a distribution with a longer tail on one side than the other. If the tail is longer on the right side, the distribution is said to be right-skewed or positively skewed. If the tail is longer on the left side, the distribution is said to be left-skewed or negatively skewed.\n",
    "3. Bimodal distribution: a distribution with two distinct peaks, indicating the presence of two subgroups or patterns in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13619632",
   "metadata": {},
   "source": [
    "\n",
    "6.\tHow do we deal with data outliers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06edae08",
   "metadata": {},
   "source": [
    "Outliers are data points that are significantly different from other observations in the dataset and can have a disproportionate impact on statistical analysis and machine learning models. Dealing with outliers depends on the context and purpose of the analysis or modeling, but here are some general approaches:\n",
    "1. Detection: Before deciding how to deal with outliers, it is important to identify them first. This can be done through visual inspection, statistical tests such as the z-score or the interquartile range (IQR), or machine learning techniques such as clustering or anomaly detection.\n",
    "2. Elimination: One common approach to dealing with outliers is to remove them from the dataset. This can be appropriate if the outliers are due to measurement errors or other anomalies, and if their removal does not significantly affect the overall distribution of the data or the analysis results. However, removing too many outliers can also result in a loss of valuable information, especially if they are genuine observations that represent a rare event or a unique pattern.\n",
    "3. Transformation: Another approach to dealing with outliers is to transform the data to reduce the impact of the outliers. This can be done by applying a mathematical transformation such as taking the logarithm or square root of the data, or by using non-parametric methods that are less sensitive to extreme values, such as the median instead of the mean.\n",
    "4. Handling: In some cases, it may be appropriate to keep the outliers in the dataset but handle them differently in the analysis or modeling. For example, they can be assigned a different weight or a different treatment in a regression model, or they can be analyzed separately as a distinct subgroup or category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d0ab9",
   "metadata": {},
   "source": [
    "\n",
    "9.\tWhat are the various central inclination measures? Why does mean vary too much from median in certain data sets?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5238046b",
   "metadata": {},
   "source": [
    "Central tendency measures are statistical values that summarize the center or midpoint of a distribution of data. The most commonly used central tendency measures are the mean, median, and mode.\n",
    "1. Mean: The mean is calculated by adding up all the values in a dataset and dividing by the total number of values. The mean is sensitive to outliers or extreme values in the data, as they can greatly influence its value.\n",
    "2. Median: The median is the value that separates the top half of the dataset from the bottom half. It is less sensitive to outliers than the mean, as it is only affected by the middle values in the dataset.\n",
    "3. Mode: The mode is the most frequently occurring value in the dataset. It is used mainly for categorical or nominal data, as it is not applicable to continuous numerical data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd1490e",
   "metadata": {},
   "source": [
    "\n",
    "10.\tDescribe how a scatter plot can be used to investigate bivariate relationships. Is it possible to find outliers using a scatter plot?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b39771",
   "metadata": {},
   "source": [
    "A scatter plot is a graphical representation of bivariate data that displays the relationship between two variables. It is a useful tool for investigating the correlation or association between two variables and identifying patterns or trends in the data.\n",
    "To create a scatter plot, one variable is plotted on the x-axis, and the other variable is plotted on the y-axis. Each point on the plot represents a pair of values from the two variables. The position of each point on the plot indicates the value of the two variables for that observation.\n",
    "A scatter plot can be used to investigate bivariate relationships in several ways:\n",
    "1. Correlation: The scatter plot can show whether there is a positive or negative correlation between the two variables. If the points on the plot are clustered in a diagonal line from the lower left to the upper right, this indicates a positive correlation. If the points are clustered in a diagonal line from the upper left to the lower right, this indicates a negative correlation.\n",
    "2. Outliers: A scatter plot can also be used to identify outliers, which are data points that are significantly different from the other observations. Outliers can be identified by points that are far away from the majority of the other points on the plot.\n",
    "3. Patterns and trends: A scatter plot can also show any patterns or trends in the data, such as a curve or a cluster of points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dc897",
   "metadata": {},
   "source": [
    "\n",
    "11.\tDescribe how cross-tabs can be used to figure out how two variables are related.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f19d338",
   "metadata": {},
   "source": [
    "Cross-tabulation, or crosstabs for short, is a statistical technique that is used to explore the relationship between two variables. It is a useful tool for investigating patterns and trends in the data, and for identifying any associations or dependencies between the variables.\n",
    "Crosstabs involve creating a table that summarizes the frequency of observations for each combination of values of two variables. One variable is usually placed along the rows of the table, and the other variable is placed along the columns. The number of observations that fall into each category of the table is then counted and displayed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e148d",
   "metadata": {},
   "source": [
    "Crosstabs can be used to answer questions such as:\n",
    "1. How are two variables related to each other?\n",
    "2. Is there a pattern or trend in the data for each combination of the variables?\n",
    "3. Are the variables independent or dependent on each other?\n",
    "To use crosstabs to explore the relationship between two variables, follow these steps:\n",
    "1. Choose the two variables that you want to investigate and define their categories.\n",
    "2. Create a table that shows the frequency of observations for each combination of values of the two variables.\n",
    "3. Calculate the percentage of observations that fall into each category of the table.\n",
    "4. Analyze the table to identify any patterns, trends, or relationships between the variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df2eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
